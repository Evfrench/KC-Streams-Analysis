---
title: "KC Analysis Methods Draft"
author: "Em French"
date: "2023-05-04"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(forecast)
library(EGRET)
library(EGRETci)
library(MARSS)
library(marssTMB)
library(tidyverse)
library(dplyr)
library(data.table)
library(smwrBase)
library(timetk)
source('./functions/get_socrata_data_func.R')
```

# Wrangle Data

```{r wrangle data}
####################################
#
# Start of Scripting and Plot Making 
#
####################################
  
# Query Socrata for the chosen site records, in this case Green River, Cedar River, and Issaquah Creek
# Need to... Call? Initialize? the funtions
GreenRiverData<- get_socrata_data_func(locns = c('A319'),
  parms = default_data_parms,
  SiteType = 'Streams and Rivers'
)

# We can normalize and make the reading more accessible py passing raw data through this function
GreenRiverDataExpanded = normalize_water_quality_data_parameters(GreenRiverData)

# Arrange the Rows by Collection date
GreenRiverDataExpanded <- arrange(GreenRiverDataExpanded,GreenRiverDataExpanded$CollectDate)

# There are two fields for DO, KC determine they have comparable detection results
# That means we can merge the two columns
GreenRiverDataExpanded$Dissolved_Oxygen <- GreenRiverDataExpanded$Dissolved_Oxygen + GreenRiverDataExpanded$`Dissolved_Oxygen,_Field`

# Merge the log values as well
GreenRiverDataExpanded$Dissolved_Oxygen_log <- GreenRiverDataExpanded$Dissolved_Oxygen_log + GreenRiverDataExpanded$`Dissolved_Oxygen,_Field_log`

# Remove one instance of duplicate values, will use the Dissolved_Oxygen sample because it was collected regularly at this point
GreenRiverDataExpanded$Dissolved_Oxygen[267] <- GreenRiverDataExpanded$Dissolved_Oxygen[267] - GreenRiverDataExpanded$`Dissolved_Oxygen,_Field`[267]
GreenRiverDataExpanded$Dissolved_Oxygen_log[267] <- GreenRiverDataExpanded$Dissolved_Oxygen_log[267] - GreenRiverDataExpanded$`Dissolved_Oxygen,_Field_log`[267]

# Load discharge records from cached CSV
green_river_daily_averages <- fread('./data_cache/green_river_daily_averages.csv')

```

# Initial Plots

These plot show a large gap from \~2008 to \~2012 There are a lot of 0's
in the data set because two columns are merged, these need to be removed

```{r River Plots}
#Create Dissolved Oxygen Plots

GreenRiverDataExpanded %>%
  ggplot(aes(x=CollectDate, y=Dissolved_Oxygen)) +
  geom_line() +
  ggtitle("Green River DO")

green_river_daily_averages %>%
  ggplot(aes(x=Date, y=LogQ)) +
  geom_line() +
  ggtitle("Green River Daily Flows")

```

## Formatting to fit the models

From the WRTDS_Sample_Workflow file, it looks like the sample dataframe
needs a number of fields that were not imported from the KC database, so
they have to be added manually

The initial window 

```{r format data for WRTDS}
# Pull out Just the stuff we need and replace the 0's with empty values
GreenDO <- subset(GreenRiverDataExpanded, select = c(CollectDate, Year, Month, Dissolved_Oxygen))
GreenDO <- replace(GreenDO, GreenDO==0, NA)
GreenDO <- GreenDO %>% 
  rename(Date = CollectDate,
         ConcAve = Dissolved_Oxygen)

# Add all of the missing fields for WRTDS
GreenDO$ConcLow <- GreenDO$ConcAve
GreenDO$ConcHigh <- GreenDO$ConcAve
GreenDO$DecYear <- decimal_date(GreenDO$Date)
GreenDO$SinDY <- sin(2*pi*GreenDO$DecYear)
GreenDO$CosDY <- cos(2*pi*GreenDO$DecYear)
GreenDO$Uncen <- NA
GreenDO$Uncen <- c(1)
GreenDO$Date <- as_date(GreenDO$Date)
GreenDO$RefDate <- as_date("1850-01-01")
GreenDO$Julian<- difftime(GreenDO$Date, GreenDO$RefDate, units = "days")
GreenDO$Julian <- as.integer(GreenDO$Julian)
GreenDO$MonthSeq <- interval(GreenDO$RefDate, GreenDO$Date) %/% months(1)
GreenDO$waterYear <- waterYear(GreenDO$Date, numeric = FALSE)

#Quick plot of new data
GreenDO %>%
  ggplot(aes(x=Date, y=ConcAve)) +
  geom_line() +
  ggtitle("Green River DO")
```

Much better, This almost looks like the DO is steadily decreasing or
staying constant

# WRTDS

The model appears to converge. I still need to do some diagnostics

```{r WRTDS Attempt}

yr_frst <- as_date("1985-01-01")
yr_last <- as_date("2022-12-31")
GreenDO <- GreenDO[GreenDO[, "Date"] >= yr_frst & GreenDO[, "Date"] <= yr_last,]
row.names(GreenDO) <- NULL
# Gather discharge data:
siteID <- "12113000" #Green River in Auburn, WA

# Gather sample data:
parameter_cd<-"00300" #5 digit USGS code, this is the dissolved oxygen
#Sample <- readNWISSample(siteID,parameter_cd,startDate,endDate) We collected this from the 
#Sample <- generate_egret_sample_from_water_quality_data(GreenRiverDataExpanded, unique(GreenRiverData$Parameter)) Commenting out until it works
Sample <- na.omit(GreenDO) #The sample data cannot be retrieve from the NWIS because it 
# comes from King County
# Example of generating egret sample data from the expanded ds
#Sample = NULL
#Sample  = generate_egret_sample_from_water_quality_data(GreenRiverDataExpanded, "Total_Alkalinity")
row.names(Sample) <- NULL
# Gather discharge data:
# The Green River Gauge is actually 3.5km downstream from the King County site,
# Another creek merges with it during that time, so we must subtract those discharges
# The corrected discharge data were collected and stored in the cache, so we need to
# import the data and replace all the discharge values with those in the .csv

Daily <- readNWISDaily(siteID,"00060",yr_frst,yr_last)

Daily$Q <- green_river_daily_averages$Q
Daily$LogQ <- green_river_daily_averages$LogQ
Daily$Q7 <- green_river_daily_averages$Q7
Daily$Q30 <- green_river_daily_averages$Q30



# Gather site and parameter information:
# Here user must input some values for
# the default (interactive=TRUE)
INFO<- readNWISInfo(siteID,parameter_cd)
INFO$shortName <- "Green River at Aurburn, WA"

# Merge discharge with sample data:
eList <- mergeReport(INFO, Daily, Sample)

# Run WRTDS model:
eList <- modelEstimation(eList)

# Test some of the plotting functions:
plotConcTimeDaily(eList)

plotConcHist(eList)

# Why aren't some of these working?
egretsurfaces <- eList[["surfaces"]]
EGRET::multiPlotDataOverview(eList = eList)
EGRET::dataOverview(Daily, Sample)
EGRET::plot15(eList, yr_frst, yr_last) #This function is not working currently
EGRET::errorStats(eList) #Neither is thnis one
```
The model has converged, excellent!
Next steps: Dig into the "surfaces" array and extract any data available.
Targets: response variable estimates, coefficient values, R-squared or other model fit data, confidence intervals, residuals.





# DLM

Everything should be in the correct form? The model took about half an
hour to run 1000 iterations but it failed to converge.

1st Attempt to fix: switch to marssTMB with the same data structure, using TMB prevents me from setting the intercept to be constant
  Results: MARSS still ran for 20 plus minutes so I quit before it finished

2nd Attempt: Use marssTMB and compress covariates down to monthly averages
  Results: The model has converged! This does use only monthly averages. I am a little concerned this model may be too "flattened" but we will see
  
3rd Attempt: Changed window to 1975-2022, this is essentially the entire record of Green River. The model output gave multiple NaN warnings and failed to converge. (specifically, it gave a false convergence warning). 

4th Attempt: Changed window to 1985-2022 in order to cut off some empty fields. I need to get records of exactly when the tech boom and urban consolidation. Best guess is 1990s? 5 years prior should work

```{r DLM Attempt}
# Merge the water quality (Sample) and the discharge (Daily) frames
# Discharge dataframe has daily records, while the quality frame has bi-monthly
# This means the response variable will have lots of missing entries
marsFrame <- data_frame()
marsFrame <- full_join(Sample, Daily, by = "Date") 
marsFrame <- arrange(marsFrame,marsFrame$Date)
marsFrame$SinDY <- sin(2*pi*marsFrame$DecYear.y) # Fill in the sin and cos of 
marsFrame$CosDY <- cos(2*pi*marsFrame$DecYear.y) # the decimal year to have daily reports
yearFrame <- marsFrame %>%
  summarise_by_time(
    .date_var = Date,
    .by = "14 days",
    .week_start = NULL,
    decyear = mean(DecYear.y)
  )
QFrame<- marsFrame %>% 
  summarise_by_time(
    .date_var = Date,
    .by = "14 days",
    .week_start = NULL,
    LogQ = mean(LogQ)
  )
sineFrame<- marsFrame %>% 
  summarise_by_time(
    .date_var = Date,
    .by = "14 days",
    .week_start = NULL,
    SinDY = mean(SinDY)
  )
cosFrame<- marsFrame %>% 
  summarise_by_time(
    .date_var = Date,
    .by = "14 days",
    .week_start = NULL,
    CosDY = mean(CosDY)
  )
DOFrame<- marsFrame %>% 
  summarise_by_time(
    .date_var = Date,
    .by = "14 days",
    .week_start = NULL,
    logDO = log(mean(ConcAve, na.rm = TRUE))
  )
# Compress all the data into monthly averages
yearFrame <- marsFrame %>% mutate(month = as.Date(Date, "%B")) %>%
    group_by(MonthSeq.y) %>%
    summarize(decyear = as.double((mean(DecYear.y))))
QFrame <- marsFrame %>% mutate(month = as.Date(Date, "%B")) %>%
    group_by(MonthSeq.y) %>%
    summarize(LogQ = as.double(mean(LogQ))) 
sineFrame <- marsFrame %>%  mutate(month = as.Date(Date, "%B")) %>%
    group_by(MonthSeq.y) %>%
    summarize(SinDY = as.double(mean(SinDY)))
cosFrame <- marsFrame %>%  mutate(month = as.Date(Date, "%B")) %>%
    group_by(MonthSeq.y) %>%
    summarize(CosDY = as.double(mean(CosDY)))
DOFrame <- marsFrame %>%  mutate(month = as.Date(Date, "%B")) %>%
  group_by(MonthSeq.y) %>%
    summarize(logDO = as.double(log(mean(ConcAve, na.rm = TRUE))))

TT = nrow(DOFrame)

# Response variable: log(Dissolved Oxygen)
DOFrame$logDO[is.nan(DOFrame$logDO)] <- NA
DO = t(DOFrame$logDO)

#Covariates: Time(as the decimal year), Daily ave discharge (logQ), seasonal effects (sin and cos of the decimal year)
Z = array(NA,c(1,5,TT))
Z[1,1,] = c(1)
Z[1,2,] = yearFrame$decyear
Z[1,3,] = QFrame$LogQ
Z[1,4,] = sineFrame$SinDY
Z[1,5,] = cosFrame$CosDY

modlist = list( #all other arguments are left at default
  Z = Z,
  U = "zero",
  A = "zero",
  B = "identity",
  Q = "diagonal and unequal"
)
# initial effects were set to 0, maybe 1 would be better
marsfit <- MARSS(DO, model = modlist, inits = list(x0 = matrix(c(0),5,1)),  control = list(maxit=3000)
                , method = "TMB"
                 )


```
The Model has successfully converged, I would like to get a visual comparison, look at r-squared values, and compare the change in effects over time. (1976-2009)

```{r}
QFrame %>%
  ggplot(aes(x=Date, y=LogQ)) +
  geom_line() +
  ggtitle("Monthly Discharge")

marsFrame %>%
  ggplot(aes(x=Date, y=LogQ)) +
  geom_line() +
  ggtitle("Daily Discharge")

```

```{r Residuals}
plotResidPred(eList)
#resids <- MARSSresiduals(marsfit)
plotConcTimeDaily(eList)
autoplot.marssMLE(marsfit)
```
MARSS DLM Residuals: 
(1976-2009) Response residuals appear to have tails indicating the error distribution is not Gaussian. States (the effects matrix for covariates) appear to be mostly constant except for x3 (log-discharge) and x5 (cosine seasonality). x5 residuals have a significant tail at the lower end. This appears to be caused by the large dip around time point 350

(1985-2022) Both ends of the response residuals are 
Further plan: This analysis will focus on temperature and DO of KC water bodies. Our hypothesis is that water quality metrics have been staying constant despite increasing temperature, and this is due to improvements in water management practices such as increased stormwater infrastrucure, more awareness of water quality by locals, etc. (quantifying this will be challenging, as of now we need to determine if there even is a long term trend)

Addendum: Move the window of years you want to analyze to more recent times. Apparently the missing 4 years should not bias the data too much, at least for the MARSS model. Need to check how this missing data will affect the WRTDS model.